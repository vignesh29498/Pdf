import pdfplumber
import difflib

def extract_text_per_page(pdf_path):
    """Extracts all text from each page and returns a combined list of words"""
    all_text = []
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            words = text.split()  # Splitting by space to ignore line breaks
            all_text.extend(words)
    return all_text

def compare_pdfs(pdf1_path, pdf2_path):
    """Compares two PDFs and categorizes deviations"""
    pdf1_words = extract_text_per_page(pdf1_path)
    pdf2_words = extract_text_per_page(pdf2_path)

    accepted_deviations = []
    not_accepted_deviations = []

    # Check for missing and extra words
    diff = list(difflib.unified_diff(pdf1_words, pdf2_words, lineterm=''))

    for line in diff:
        if line.startswith("- "):  # Missing in PDF 2
            not_accepted_deviations.append(f"Missing text in PDF 2: {line[2:]}")
        elif line.startswith("+ "):  # Extra in PDF 2
            not_accepted_deviations.append(f"Extra text in PDF 2: {line[2:]}")

    # Check if words exist anywhere (position ignored)
    for word in pdf1_words:
        if word in pdf2_words:
            accepted_deviations.append(f"Text found elsewhere: '{word}'")

    # Remove duplicates from accepted deviations
    accepted_deviations = list(set(accepted_deviations))

    # Output results
    print("\n=== Accepted Deviations ===")
    if accepted_deviations:
        for deviation in accepted_deviations:
            print(deviation)
    else:
        print("No accepted deviations found.")

    print("\n=== Not Accepted Deviations ===")
    if not_accepted_deviations:
        for deviation in not_accepted_deviations:
            print(deviation)
    else:
        print("No not-accepted deviations found.")

# Example usage
pdf1 = "sample1.pdf"
pdf2 = "sample2.pdf"
compare_pdfs(pdf1, pdf2)
